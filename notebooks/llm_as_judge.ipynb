{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import json\n",
    "from groq import Groq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "judge_client = Groq(\n",
    "    api_key=os.environ.get(\"GROQ_API_KEY\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def judge_llm(prompt):\n",
    "    start_time = time.time()\n",
    "    response = judge_client.chat.completions.create(\n",
    "        model=\"llama-3.1-70b-versatile\",\n",
    "        messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": prompt,\n",
    "        }\n",
    "    ])\n",
    "    answer = response.choices[0].message.content\n",
    "    tokens = {\n",
    "            'prompt_tokens': response.usage.prompt_tokens,\n",
    "            'completion_tokens': response.usage.completion_tokens,\n",
    "            'total_tokens': response.usage.total_tokens\n",
    "        }\n",
    "    end_time = time.time()\n",
    "    response_time = end_time - start_time\n",
    "    return answer, tokens, response_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_response(question, answer):\n",
    "    prompt_template = \"\"\"\n",
    "    You will be given a user_question and system_answer couple.\n",
    "    Your task is to provide a 'total rating' scoring how well the system_answer answers the user concerns expressed in the user_question.\n",
    "    Give your answer on a scale of 1 to 4, where 1 means that the system_answer is not helpful at all, and 4 means that the system_answer completely and helpfully addresses the user_question.\n",
    "\n",
    "    Here is the scale you should use to build your answer:\n",
    "    1: The system_answer is terrible: completely irrelevant to the question asked, or very partial\n",
    "    2: The system_answer is mostly not helpful: misses some key aspects of the question\n",
    "    3: The system_answer is mostly helpful: provides support, but still could be improved\n",
    "    4: The system_answer is excellent: relevant, direct, detailed, and addresses all the concerns raised in the question\n",
    "\n",
    "    Provide your feedback as follows:\n",
    "\n",
    "    Feedback:::\n",
    "    Evaluation: (your rationale for the rating, as a text)\n",
    "    Total rating: (your rating, as a number between 1 and 4)\n",
    "\n",
    "    You MUST provide values for 'Feedback' and 'Rating' in your answer.\n",
    "\n",
    "    Now here are the question and answer.\n",
    "\n",
    "    Question: {question}\n",
    "    Generated Answer: {answer}\n",
    "\n",
    "    Please analyze the content and context of the generated answer in relation to the question\n",
    "    and provide your evaluation in parsable JSON without using code blocks:\n",
    "\n",
    "    {{\n",
    "      \"Feedback\": \"[Provide a brief explanation for your evaluation]\",\n",
    "      \"Rating\": [Provide the evaluation between 1 to 4]\n",
    "    }}\n",
    "    \"\"\".strip()\n",
    "    prompt = prompt_template.format(question=question, answer=answer)\n",
    "    evaluation, tokens, _ = judge_llm(prompt)\n",
    "    try:\n",
    "        json_eval = json.loads(evaluation)\n",
    "        return json_eval['Feedback'], json_eval['Rating'], tokens\n",
    "    except json.JSONDecodeError:\n",
    "        return \"Failed to parse evaluation\", 0, tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"\"\"Explain how a convolutional network works\"\"\"\n",
    "answer = \"\"\"A convolutional network works by applying multiple convolutions to the input data, creating multiple channels at each spatial position. These channels are then combined and downsampled by a factor of two, increasing the number of channels. This process is repeated, with the spatial dimensions decreasing and the channels increasing. The network typically ends with fully connected layers that integrate information from across the input to create the desired output.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "feedback,rating,tokens = evaluate_response(question, answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The system answer provides a general overview of the components and process involved in a convolutional network, but it is somewhat technical and lacks specific details and explanations about key concepts such as convolutions, downsampling, and fully connected layers. However, it still addresses the main question and provides a clear framework of how the network works.\n"
     ]
    }
   ],
   "source": [
    "print(feedback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "print(rating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'prompt_tokens': 446, 'completion_tokens': 80, 'total_tokens': 526}\n"
     ]
    }
   ],
   "source": [
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llmprj_1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
