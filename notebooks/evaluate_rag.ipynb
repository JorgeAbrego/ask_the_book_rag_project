{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/llmprj_1/lib/python3.10/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:11: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm, trange\n",
      "/home/ubuntu/miniconda3/envs/llmprj_1/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import ast\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_postgres import PGVector\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain.schema.output_parser import StrOutputParser\n",
    "from datasets import Dataset\n",
    "\n",
    "sys.path.append('../..')\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file\n",
    "\n",
    "PG_VECTOR_PWD = os.environ[\"PG_VECTOR_PWD\"]\n",
    "\n",
    "model_embedding = HuggingFaceEmbeddings(model_name='multi-qa-mpnet-base-dot-v1')\n",
    "\n",
    "connection = f\"postgresql+psycopg://vector_user:{PG_VECTOR_PWD}@localhost:5431/vector_db\"\n",
    "collection_name = \"udlbook\"\n",
    "\n",
    "vector_store = PGVector(\n",
    "    embeddings=model_embedding,\n",
    "    collection_name=collection_name,\n",
    "    connection=connection,\n",
    "    use_jsonb=True,\n",
    ")\n",
    "\n",
    "retriever = vector_store.as_retriever(search_kwargs={'k': 3})\n",
    "\n",
    "llm = ChatGroq(\n",
    "    model=\"llama-3.1-70b-versatile\",\n",
    "    temperature=0,\n",
    "    max_tokens=None,\n",
    "    timeout=None,\n",
    "    max_retries=2,\n",
    ")\n",
    "\n",
    "prompt = \"\"\"You are an expert in the book 'Understanding Deep Learning'. \n",
    "Use the following pieces of retrieved context to answer the question.\n",
    "If you don't know the answer, just say that you don't know.\n",
    "Keep the answer upto 5 lines unless the user asks for more information\n",
    "\n",
    "Question:\n",
    "{question}\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Answer:\n",
    "\"\"\"\n",
    "\n",
    "prompt_template = ChatPromptTemplate.from_template(prompt)\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "qa_rag_chain = (\n",
    "{\"context\": (retriever | format_docs), \"question\": RunnablePassthrough()}\n",
    "| prompt_template\n",
    "| llm\n",
    "| StrOutputParser() \n",
    ")\n",
    "\n",
    "query = 'What is machine learning'\n",
    "result = qa_rag_chain.invoke(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from ragas import evaluate\n",
    "from ragas.metrics import (\n",
    "    answer_relevancy,\n",
    "    faithfulness,\n",
    "    context_recall,\n",
    "    context_precision,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data = pd.read_csv(\"../files/evaluation_dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseset = df_data[['question','contexts','ground_truth']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseset['contexts']=baseset['contexts'].apply(ast.literal_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How are node embeddings updated in a simple Graph CNN layer?\n",
      "In a simple Graph CNN layer, node embeddings are updated by: \n",
      "1. aggregating neighboring nodes to form a vector, \n",
      "2. applying a linear transformation to the aggregated vector and the original node, \n",
      "3. adding these together with a bias, \n",
      "4. and finally applying a nonlinear activation function.\n",
      "\n",
      "What is an adjacency matrix in graph representation, and how is it defined?\n",
      "An adjacency matrix in graph representation is a matrix A where entry (m, n) is set to one if there is an edge between nodes m and n, and zero otherwise. It is an N × N matrix representing the graph structure. For undirected graphs, this matrix is always symmetric.\n",
      "\n",
      "What is the relationship between the least squares criterion and the fit of a linear model?\n",
      "The least squares criterion minimizes the sum of the squares of the deviations between the model prediction and the true output values. A good fit results in small squared deviations, while a bad fit results in large squared deviations. The least squares criterion follows from the assumption that the model predicts the mean of a normal distribution over the outputs and that we maximize the probability.\n",
      "\n",
      "What are the desiderata for network layers in normalizing flows?\n",
      "The desiderata for network layers in normalizing flows are: \n",
      "1. Expressiveness to map a multivariate standard normal distribution to an arbitrary density.\n",
      "2. Invertibility, defining a unique one-to-one mapping from input to output.\n",
      "3. Efficient computation of the inverse of each layer.\n",
      "4. Efficient evaluation of the determinant of the Jacobian for either the forward or inverse mapping.\n",
      "\n",
      "What is the role of the diffusion kernel q(zt|x) in the diffusion encoder process?\n",
      "The diffusion kernel q(zt|x) is a probability distribution over variable zt given that we started from x. It allows us to sample a latent variable zt corresponding to a given x without computing the intermediate variables z1, . . . , zt−1.\n",
      "\n",
      "Backpropagation method for neural nets?\n",
      "The backpropagation method for neural nets involves two main steps: \n",
      "1. Forward pass: computing and storing the network's output and intermediate values.\n",
      "2. Backward pass: computing the derivatives of the loss function with respect to the network's parameters (biases and weights) by working backward through the network.\n",
      "\n",
      "Loss functions for graph regression & binary classification?\n",
      "For graph regression, the loss function is the least squares loss. \n",
      "For binary classification, the loss function is the binary cross-entropy loss.\n",
      "\n",
      "How can a 2-hidden-layer network be broken down into 2 shallow ones?\n",
      "A 2-hidden-layer network can be broken down into 2 shallow ones by considering the output of the first shallow network as the input to the second shallow network. This is because the output of the first layer (h1, h2, h3) serves as the input to the second layer (h′1, h′2, h′3).\n",
      "\n",
      "What is the role of a linear transformation in a simple Graph CNN layer?\n",
      "The role of a linear transformation in a simple Graph CNN layer is to transform the aggregated vector and the original node vector. It is applied to both the aggregated vector and the original node vector, denoted as Ω0.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "answers_lst = []\n",
    "\n",
    "for index,row in baseset.iterrows():\n",
    "    print(row['question'])\n",
    "    result = qa_rag_chain.invoke(row['question'])\n",
    "    print(result)\n",
    "    answers_lst.append(result)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseset['answer'] = answers_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "datatest = Dataset.from_pandas(baseset[['question', 'contexts', 'answer', 'ground_truth']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de01fc85a12f42a28ef9c1349b80c53b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/36 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception raised in Job[29]: TimeoutError()\n",
      "Exception raised in Job[19]: TimeoutError()\n",
      "Exception raised in Job[20]: TimeoutError()\n",
      "Exception raised in Job[3]: TimeoutError()\n",
      "Exception raised in Job[23]: TimeoutError()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'context_precision': 1.0000, 'faithfulness': 0.9125, 'answer_relevancy': 0.9474, 'context_recall': 1.0000}"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = evaluate(\n",
    "    dataset=datatest,\n",
    "    metrics=[\n",
    "        context_precision,\n",
    "        faithfulness,\n",
    "        answer_relevancy,\n",
    "        context_recall,\n",
    "    ],\n",
    "    llm=llm,\n",
    "    embeddings=model_embedding,\n",
    ")\n",
    "\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llmprj_1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
